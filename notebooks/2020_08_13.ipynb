{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# August 13, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning by row types\n",
    "\n",
    "The data for this project is in the HURDAT2 format from NHC. This format contains rows of storm positions interspersed with header rows denoting which storm the subsequent position data corresponds to.\n",
    "\n",
    "Because of this, the raw data table has a few problems:\n",
    "- No column names are provided.\n",
    "- Columns contain a mix of data types.\n",
    "- Many rows are full of missing data for most columns.\n",
    "\n",
    "As a result, our first goal will be to convert the data into a more usable format. We begin by importing the raw data as is into a Pandas DataFrame, `atl`. In doing so, we also assign column names which correspond to the information in the storm position data rows. We will later separate the header rows into a new DataFrame and assign them their own column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>recordID</th>\n",
       "      <th>status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>maxSustWind</th>\n",
       "      <th>minPressure</th>\n",
       "      <th>extNE34</th>\n",
       "      <th>extSE34</th>\n",
       "      <th>extSW34</th>\n",
       "      <th>extNW34</th>\n",
       "      <th>extNE50</th>\n",
       "      <th>extSE50</th>\n",
       "      <th>extSW50</th>\n",
       "      <th>extNW50</th>\n",
       "      <th>extNE64</th>\n",
       "      <th>extSE64</th>\n",
       "      <th>extSW64</th>\n",
       "      <th>extNW64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18510625</td>\n",
       "      <td>0000</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0N</td>\n",
       "      <td>94.8W</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18510625</td>\n",
       "      <td>0600</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0N</td>\n",
       "      <td>95.4W</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18510625</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0N</td>\n",
       "      <td>96.0W</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18510625</td>\n",
       "      <td>1800</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1N</td>\n",
       "      <td>96.5W</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date                 time recordID status     lat      lon  \\\n",
       "0  AL011851              UNNAMED       14    NaN     NaN      NaN   \n",
       "1  18510625                 0000              HU   28.0N    94.8W   \n",
       "2  18510625                 0600              HU   28.0N    95.4W   \n",
       "3  18510625                 1200              HU   28.0N    96.0W   \n",
       "4  18510625                 1800              HU   28.1N    96.5W   \n",
       "\n",
       "   maxSustWind  minPressure  extNE34  extSE34  extSW34  extNW34  extNE50  \\\n",
       "0          NaN          NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "1         80.0       -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "2         80.0       -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "3         80.0       -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "4         80.0       -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "\n",
       "   extSE50  extSW50  extNW50  extNE64  extSE64  extSW64  extNW64  \n",
       "0      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0  \n",
       "2   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0  \n",
       "3   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0  \n",
       "4   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0   -999.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# These steps will apply both to Atlantic and Pacific datasets, so when\n",
    "# we ultimately convert these steps into a function we'll allow the\n",
    "# user to provide a filename. The function will always search in the\n",
    "# raw data directory, so the filename alone will differentiate between\n",
    "# the raw datasets.\n",
    "\n",
    "# In this case, we'll set up the framework but assign the filename\n",
    "# ourselves so we can test the code.\n",
    "fn = 'Atlantic.csv'\n",
    "# We're going to save the two new datasets that result from splitting\n",
    "# the HURDAT file as separate files, so we'll use os.path.splitext to \n",
    "# separate the filename and extension for the raw data, then store the\n",
    "# filename to use in appropriately naming the resulting files.\n",
    "fn_no_ext = os.path.splitext(fn)[0]\n",
    "\n",
    "# This list of column names applies to the position data rows.\n",
    "header = ['date', 'time', 'recordID', 'status', 'lat', 'lon', 'maxSustWind', 'minPressure', 'extNE34', 'extSE34', 'extSW34', 'extNW34', 'extNE50', 'extSE50', 'extSW50', 'extNW50', 'extNE64', 'extSE64', 'extSW64', 'extNW64']\n",
    "\n",
    "# Import data from raw data folder using our column names, and verify \n",
    "# that we got the right data.\n",
    "hurdat = pd.read_csv(f'../data/01_raw/{fn}', names = header)\n",
    "hurdat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the [NHC documentation](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-nov2019.pdf) for the HURDAT2 database, column names are as follows:\n",
    "\n",
    "- `date`: timecode for the position entry, format `YYYYMMDD`\n",
    "- `time`: timecode for the position entry, format `HHMM` in 24-Hr UTC\n",
    "- `recordID`: special designation for significant position entries. Can be empty or contain values:\n",
    " - **C**: closest approach to coast when not followed by landfall\n",
    " - **G**: genesis\n",
    " - **I**: intensity peak in both pressure and wind\n",
    " - **L**: landfall\n",
    " - **P**: minimum pressure\n",
    " - **R**: additional intensity detail during rapid changes\n",
    " - **S**: change of status\n",
    " - **T**: additional track/position detail\n",
    " - **W**: maximum wind speed\n",
    "- `status`: tropical depression, tropical storm, hurricane, extratropical cyclone, subtropical depression, subtropical storm, low pressure system, tropical wave, or disturbance\n",
    "- `lat`: latitude of center of storm\n",
    "- `lon`: longitude of center of storm\n",
    "- `maxSustWind`: maximum sustained wind\n",
    "- `minPressure`: minimum central pressure\n",
    "- `extDDXX`: extent of `XX` nautical mile per hour (knots) winds in the `DD` cardinal direction quadrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to separate the rows of `atl` into two new DataFrames, `storms` for header rows and `positions` for position data. We can do this easily by examining the `date` column. In rows containing position data, this column contains an entirely numeric string as described above. In header rows, this column contains alphabetic characters denoting the ocean basin the storm occurred in. We can use this property to easily flag header rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to determine which rows go in which new DataFrame, so create\n",
    "# a list that can be turned into a series and added as a new column.\n",
    "header = []\n",
    "\n",
    "# If there are only numeric characters in the date column, this is\n",
    "# a position row. Otherwise, flag the row as being a header row.\n",
    "for entry in hurdat['date']:\n",
    "    if entry.isnumeric():\n",
    "        header.append(False)\n",
    "    else:\n",
    "        header.append(True)\n",
    "\n",
    "# Cast the list as a pandas series and add it as a column of DataFrame.\n",
    "hurdat['header'] = pd.Series(header) \n",
    "\n",
    "# Create DataFrames of only header rows and only position data so we \n",
    "# can prepare each appropriately.\n",
    "storms = hurdat[hurdat['header'] == True].copy() # All header columns of atl copied into new dataframe storms.\n",
    "positions = hurdat[hurdat['header'] == False].copy() # All data columns of atl copied into new dataframe positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our DataFrames, `storms` and `positions`, each one needs a bit more preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storms dataframe\n",
    "The header rows contain some important information, but require many fewer columns than position data rows, so we'll eliminate the excess columns and rename the remaining ones appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stormID</th>\n",
       "      <th>name</th>\n",
       "      <th>numPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL021851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL031851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL041851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL051851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stormID                 name numPositions\n",
       "0  AL011851              UNNAMED           14\n",
       "1  AL021851              UNNAMED            1\n",
       "2  AL031851              UNNAMED            1\n",
       "3  AL041851              UNNAMED           49\n",
       "4  AL051851              UNNAMED           16"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns, including the column indicating header rows.\n",
    "storms.drop(['status', 'lat', 'lon', 'maxSustWind', 'minPressure', 'extNE34', 'extSE34', 'extSW34', 'extNW34', 'extNE50', 'extSE50', 'extSW50', 'extNW50', 'extNE64', 'extSE64', 'extSW64', 'extNW64', 'header'], axis = 1, inplace = True)\n",
    "# Rename remaining columns.\n",
    "storms.columns = ['stormID', 'name', 'numPositions']\n",
    "# Reset indices to fill in gaps from position rows.\n",
    "storms.reset_index(drop=True, inplace=True)\n",
    "# Check the result.\n",
    "storms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the remaining columns, based on the [NHC documentation](https://www.nhc.noaa.gov/data/hurdat/hurdat2-format-nov2019.pdf):\n",
    "\n",
    "- `stormID`: an individual identifier for each storm in the form `NNXXYYYY` denoting the storm was the `XX`th storm of Hurricane Season `YYYY` in the `NN` basin (either `AL` for Atlantic, `EP` for Eastern Pacific, or `CP` for Central Pacific). Particularly useful when storms in different years share the same name, and for unnamed storms.\n",
    "- `name`: name of storm.\n",
    "- `numPositions`: the number of position entries in positions DataFrame corresponding to this storm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new columns still need to be assigned the correct data types, and some require cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stormID</th>\n",
       "      <th>name</th>\n",
       "      <th>numPositions</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL011851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>14</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL021851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AL031851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>1</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL041851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>49</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL051851</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>16</td>\n",
       "      <td>1851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stormID     name  numPositions  year\n",
       "0  AL011851  UNNAMED            14  1851\n",
       "1  AL021851  UNNAMED             1  1851\n",
       "2  AL031851  UNNAMED             1  1851\n",
       "3  AL041851  UNNAMED            49  1851\n",
       "4  AL051851  UNNAMED            16  1851"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We're going to want storms to easily be subsettable by years, so we'll\n",
    "# create a new numeric column for it and fill the entries by parsing \n",
    "# the entries of the stormID column.\n",
    "stormYears = []\n",
    "\n",
    "# We can pull out the year easily since all the stormIDs share the same\n",
    "# format. Note that this year corresponds to the storm season, but\n",
    "# that it is possible under rare circumstances for storms to\n",
    "# persist into the following year so the dates on position entries may\n",
    "# not always show the year presented here.\n",
    "for stormID in storms['stormID']:\n",
    "    stormYears.append(stormID[4:9]) \n",
    "\n",
    "# Assign new year column integer dtype.\n",
    "storms['year'] = pd.Series(stormYears).astype('int') \n",
    "# Reassign number of positions integer dtype.\n",
    "storms['numPositions'] = storms['numPositions'].astype('int')\n",
    "# Strip whitespace from name and stormID values.\n",
    "storms['name'] = storms['name'].astype('str').str.strip() \n",
    "storms['stormID'] = storms['stormID'].astype('str').str.strip()\n",
    "\n",
    "# Verify what was done to the DataFrame.\n",
    "storms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positions dataframe\n",
    "For `positions`, we need to reset the indices and reformat the latitude and longitude information to a more standardized format.\n",
    "\n",
    "For latitudes we can write `XX.XN` as `XX.X` and `XX.XS` as `-XX.X`.\n",
    "For longitudes we can write `XX.XE` as `XX.X` and `XX.XW` as `-XX.X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index.\n",
    "positions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Create lists to be used as new series for latitude and longitude. \n",
    "numLat = [] \n",
    "numLon = []\n",
    " \n",
    "for cardLat in positions['lat']:\n",
    "    if cardLat.find('N') != -1: \n",
    "        # For latitudes of degrees North, strip the whitespace and N.\n",
    "        numLat.append(cardLat.strip(\" N\"))\n",
    "    else: \n",
    "        # For latitudes of degrees South, strip the whitespace and S \n",
    "        # and make the value negative.\n",
    "        numLat.append('-'+cardLat.strip(\" S\"))\n",
    "    \n",
    "for cardLon in positions['lon']:\n",
    "    if cardLon.find('E') != -1: \n",
    "        # For longitudes of degrees East, strip the whitespace and E.\n",
    "        numLon.append(cardLon.strip(\" E\"))\n",
    "    else: \n",
    "        # For longitudes of degrees West, strip the whitespace and W \n",
    "        # and make the value negative.\n",
    "        numLon.append('-'+cardLon.strip(\" W\"))\n",
    "     \n",
    "# Replace the existing longitude and latitude columns with the new ones.\n",
    "positions['lat'] = pd.Series(numLat).astype('float')\n",
    "positions['lon'] = pd.Series(numLon).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we want position entries to contain storm names and stormIDs for the sake of readability and subsettability. We can use the `numPositions` column of `storms` to populate this column easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>recordID</th>\n",
       "      <th>status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>maxSustWind</th>\n",
       "      <th>minPressure</th>\n",
       "      <th>extNE34</th>\n",
       "      <th>extSE34</th>\n",
       "      <th>...</th>\n",
       "      <th>extNE50</th>\n",
       "      <th>extSE50</th>\n",
       "      <th>extSW50</th>\n",
       "      <th>extNW50</th>\n",
       "      <th>extNE64</th>\n",
       "      <th>extSE64</th>\n",
       "      <th>extSW64</th>\n",
       "      <th>extNW64</th>\n",
       "      <th>name</th>\n",
       "      <th>stormID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18510625</td>\n",
       "      <td>0000</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-94.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>AL011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18510625</td>\n",
       "      <td>0600</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-95.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>AL011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18510625</td>\n",
       "      <td>1200</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-96.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>AL011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18510625</td>\n",
       "      <td>1800</td>\n",
       "      <td></td>\n",
       "      <td>HU</td>\n",
       "      <td>28.1</td>\n",
       "      <td>-96.5</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>AL011851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18510625</td>\n",
       "      <td>2100</td>\n",
       "      <td>L</td>\n",
       "      <td>HU</td>\n",
       "      <td>28.2</td>\n",
       "      <td>-96.8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>UNNAMED</td>\n",
       "      <td>AL011851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   time recordID status   lat   lon  maxSustWind  minPressure  \\\n",
       "0  18510625   0000              HU  28.0 -94.8         80.0       -999.0   \n",
       "1  18510625   0600              HU  28.0 -95.4         80.0       -999.0   \n",
       "2  18510625   1200              HU  28.0 -96.0         80.0       -999.0   \n",
       "3  18510625   1800              HU  28.1 -96.5         80.0       -999.0   \n",
       "4  18510625   2100        L     HU  28.2 -96.8         80.0       -999.0   \n",
       "\n",
       "   extNE34  extSE34  ...  extNE50  extSE50  extSW50  extNW50  extNE64  \\\n",
       "0   -999.0   -999.0  ...   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "1   -999.0   -999.0  ...   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "2   -999.0   -999.0  ...   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "3   -999.0   -999.0  ...   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "4   -999.0   -999.0  ...   -999.0   -999.0   -999.0   -999.0   -999.0   \n",
       "\n",
       "   extSE64  extSW64  extNW64     name   stormID  \n",
       "0   -999.0   -999.0   -999.0  UNNAMED  AL011851  \n",
       "1   -999.0   -999.0   -999.0  UNNAMED  AL011851  \n",
       "2   -999.0   -999.0   -999.0  UNNAMED  AL011851  \n",
       "3   -999.0   -999.0   -999.0  UNNAMED  AL011851  \n",
       "4   -999.0   -999.0   -999.0  UNNAMED  AL011851  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list to be used as the names column in this DataFrame\n",
    "stormNames = [] \n",
    "\n",
    "# For each storm in the storms DataFrame...\n",
    "for i in range(len(storms)): \n",
    "    # For the number of rows indicated, add the storm name to the list.\n",
    "    for j in range(storms['numPositions'][i]): \n",
    "        stormNames.append(storms['name'][i])\n",
    "               \n",
    "# And create the new column using the list.      \n",
    "positions['name'] = pd.Series(stormNames)\n",
    "\n",
    "# Repeat the process for storm IDs\n",
    "stormIDs = []\n",
    "\n",
    "for i in range(len(storms)):\n",
    "    for j in range(storms['numPositions'][i]):\n",
    "        stormIDs.append(storms['stormID'][i])\n",
    "              \n",
    "positions['stormID'] = pd.Series(stormIDs)\n",
    "\n",
    "# Remove the unnecessary header indicator column.\n",
    "positions.drop(columns=\"header\", inplace = True)\n",
    "# Verify what was done to the DataFrame.\n",
    "positions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the DataFrames\n",
    "We can now go ahead and export these new and cleaned DataFrames into the `/data/02_intermediate` directory.\n",
    "\n",
    "While a number of rows in `positions` contain missing values for the columns pertaining to the wind extent columns, these data points should be retained as they contain other useful information. When working with wind extent data, for the sake of efficiency we can subset the data before working. However, the current state of the data will suffice for the cleaning step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned Atlantic.csv into:\n",
      " /data/02_intermediate/Atlantic_positions.csv\n",
      " /data/02_intermediate/Atlantic_storms.csv\n"
     ]
    }
   ],
   "source": [
    "# We'll use the filename we stored after removing the extension earlier\n",
    "# to create the child files in the new directory.\n",
    "positions_fn = ( fn_no_ext + \"_positions.csv\" )\n",
    "positions.to_csv(f\"../data/02_intermediate/{positions_fn}\", index = False)\n",
    "\n",
    "storms_fn = ( fn_no_ext + \"_storms.csv\" )\n",
    "storms.to_csv(f\"../data/02_intermediate/{storms_fn}\", index = False)\n",
    "\n",
    "# Verify for the user which files were created.\n",
    "print(f\"Partitioned {fn} into:\\n /data/02_intermediate/{positions_fn}\\n /data/02_intermediate/{storms_fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modularizing\n",
    "We'll convert all of the above steps into a function in a new module, `clean_hurdat.py`. This module will exist in `/src/d02_intermediate`.\n",
    "\n",
    "I'll then test the new function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partitioned Atlantic.csv into:\n",
      " /data/02_intermediate/Atlantic_positions.csv\n",
      " /data/02_intermediate/Atlantic_storms.csv\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), '..')\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from src.d02_intermediate import clean_hurdat as cln\n",
    "\n",
    "cln.partition_hurdat('Atlantic.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data is usable!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
